name: Sync Registration Page to GitHub Pages

on:
  push:
    branches:
      - main  # Trigger on push to main branch
  workflow_dispatch:  # Allow manual trigger
  schedule:
    - cron: '0 0 * * *'  # Runs daily at midnight UTC

jobs:
  sync-registration:
    runs-on: ubuntu-latest
    timeout-minutes: 10  # Prevent hanging
    steps:
      # Checkout the repository
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # Set up Node.js
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      # Install Puppeteer and axios
      - name: Install dependencies
        run: npm install puppeteer@24.15.0 axios@1.7.7
        timeout-minutes: 3

      # Scrape the registration page and download assets
      - name: Scrape registration page and assets
        run: |
          mkdir -p dist
          node -e "$(cat << 'EOF'
            const puppeteer = require('puppeteer');
            const axios = require('axios');
            const fs = require('fs').promises;
            const path = require('path');
            (async () => {
              try {
                const browser = await puppeteer.launch({ headless: 'new', args: ['--no-sandbox', '--disable-setuid-sandbox'] });
                const page = await browser.newPage();
                await page.goto('https://ctxyouth.com/registration', { waitUntil: 'networkidle2', timeout: 60000 });
                
                // Get HTML
                let content = await page.content();
                
                // Extract asset URLs
                const assets = await page.evaluate(() => {
                  const urls = [];
                  const selectors = [
                    'link[href]',
                    'script[src]',
                    'img[src]',
                    'source[src]',
                    'font[src]'
                  ];
                  selectors.forEach(sel => {
                    document.querySelectorAll(sel).forEach(el => {
                      const url = el.href || el.src;
                      if (url && url.startsWith('https://ctxyouth.com/') && !url.includes('/feed/') && !url.includes('/wp-json/')) {
                        urls.push(url.split('?')[0]);
                      }
                    });
                  });
                  return [...new Set(urls)];
                });
                
                // Download assets and rewrite URLs
                for (const assetUrl of assets) {
                  try {
                    const relativePath = assetUrl.replace('https://ctxyouth.com/', '').split('?')[0];
                    const filePath = path.join('dist', relativePath);
                    console.log('Downloading:', assetUrl, 'to', relativePath);
                    await fs.mkdir(path.dirname(filePath), { recursive: true });
                    const response = await axios.get(assetUrl, { responseType: 'arraybuffer', timeout: 10000 });
                    await fs.writeFile(filePath, response.data);
                    console.log('Downloaded:', relativePath);
                    // Rewrite this specific asset URL in HTML
                    const escapedUrl = assetUrl.replace(/[.*+?^${}()|[\]\\]/g, '\\\\$&');
                    content = content.replace(new RegExp(escapedUrl.split('?')[0], 'g'), `/${relativePath}`);
                  } catch (err) {
                    console.error('Failed to download:', assetUrl, err.message);
                  }
                }
                
                // Single rewrite for remaining ctxyouth.com URLs
                content = content.replace(/https:\/\/ctxyouth\.com\//g, '/');
                
                // Save HTML to dist root
                await fs.writeFile('dist/index.html', content);
                
                // Debug: List dist contents
                const files = await fs.readdir('dist', { recursive: true });
                console.log('Dist contents:', files);
                await browser.close();
                console.log('Successfully scraped page and saved HTML with assets');
              } catch (error) {
                console.error('Error scraping page:', error);
                process.exit(1);
              }
            })();
          EOF
          )"
        timeout-minutes: 5

      # Deploy to GitHub Pages
      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: dist
          destination_dir: .
          keep_files: false
          commit_message: Sync ctxyouth.com/registration with assets to index.html
